{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:36:37.631398Z",
     "start_time": "2024-01-28T20:36:36.970531Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rohdaten importieren\n",
    "excel_file_path = '2023_eim.xlsx'\n",
    "all_sheets_dict = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "# leere Liste erstellen für die DataFrames\n",
    "all_sheets_list = []\n",
    "\n",
    "# Schleife über alle DataFrames in all_sheets_dict und diese in die Liste all_sheets_list einfügen\n",
    "for sheet_name, sheet_df in all_sheets_dict.items():\n",
    "    # Spalte 'Jahr' aus dem Sheet-Namen erstellen\n",
    "    sheet_df['Jahr'] = sheet_name\n",
    "    all_sheets_list.append(sheet_df)\n",
    "\n",
    "# Zusammenführen der DataFrames in all_sheets_list zu einem DataFrame\n",
    "combined_df = pd.concat(all_sheets_list, ignore_index=True)\n",
    "\n",
    "# Speichern des DataFrames in eine Excel-Datei\n",
    "combined_df.to_excel('2023_eim_combined.xlsx', index=False)\n",
    "\n",
    "# Erstellen eines neuen DataFrames mit der Anzahl der einzigartigen Kunden und der Summe der Tage, gruppiert nach 'Mitarbeiter' und 'Jahr'\n",
    "grouped_df = combined_df.groupby(['Mitarbeiter', 'Jahr']).agg(\n",
    "    num_customers=pd.NamedAgg(column='Anforderer', aggfunc='nunique'),\n",
    "    sum_tage=pd.NamedAgg(column='Tage', aggfunc='sum')\n",
    ").reset_index()\n",
    "\n",
    "# Speichern des gruppierten DataFrames in eine Excel-Datei\n",
    "grouped_df.to_excel('2023_eim_grouped.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die gruppierten Daten dienen als Input für die weitere Aufbereitung der Daten, zu einer Excel Datei mit den Input Features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c36e5429aa4c60e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Jahr   Name  Alter  Berufserfahrung  Anzahl Kunden  Bestandskunden  Level  \\\n",
      "0  2017  BAERJ    NaN              NaN             45             NaN    NaN   \n",
      "1  2018  BAERJ    NaN              NaN             48             NaN    NaN   \n",
      "2  2019  BAERJ    NaN              NaN             54             NaN    NaN   \n",
      "3  2020  BAERJ    NaN              NaN             50             NaN    NaN   \n",
      "4  2021  BAERJ    NaN              NaN             36             NaN    NaN   \n",
      "\n",
      "   Fehltage  Vollzeit    Tage  Arbeitstage  Wirtschaftswachstum  \\\n",
      "0       NaN       NaN  112.17          247                  2.7   \n",
      "1       NaN       NaN  123.63          249                  1.0   \n",
      "2       NaN       NaN   74.69          249                  1.1   \n",
      "3       NaN       NaN  130.47          253                 -3.8   \n",
      "4       NaN       NaN  132.96          253                  3.2   \n",
      "\n",
      "   FIS Umsatz pro Mitarbeiter  Workdays  \n",
      "0                       98658       NaN  \n",
      "1                      102865       NaN  \n",
      "2                      104651       NaN  \n",
      "3                      107317       NaN  \n",
      "4                      109112       NaN  \n"
     ]
    }
   ],
   "source": [
    "# import input features\n",
    "input_file_path = 'input_features.xlsx'\n",
    "\n",
    "input_df = pd.read_excel(input_file_path)\n",
    "arbeitstage = {2017: 247, 2018: 249, 2019: 249, 2020: 253, 2021: 253, 2022: 250, 2023: 248}\n",
    "bip_deutschland = {2017: 2.7, 2018: 1, 2019: 1.1, 2020: -3.8, 2021: 3.2, 2022: 1.8, 2023: -0.3}\n",
    "fis_turnover_per_employee = {2017: 98658, 2018: 102865, 2019: 104651, 2020: 107317, 2021: 109112, 2022: 111318, 2023: 114443}\n",
    "\n",
    "# add column 'Arbeitstage' to the dataframe according to the column 'Jahr'\n",
    "input_df['Arbeitstage'] = input_df['Jahr'].map(arbeitstage)\n",
    "# add column 'BIP Deutschland' to the dataframe according to the column 'Jahr'\n",
    "input_df['Wirtschaftswachstum'] = input_df['Jahr'].map(bip_deutschland)\n",
    "# add column 'FIS Turnover per Employee' to the dataframe according to the column 'Jahr'\n",
    "input_df['FIS Umsatz pro Mitarbeiter'] = input_df['Jahr'].map(fis_turnover_per_employee)\n",
    "# multiply the column 'Vollzeit' with the column 'Arbeitstage' and add the result to the dataframe as column 'Workdays'\n",
    "input_df['Workdays'] = input_df['Vollzeit'] * input_df['Arbeitstage']\n",
    "\n",
    "# print the head of the dataframe\n",
    "print(input_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:36:40.090466Z",
     "start_time": "2024-01-28T20:36:40.064018Z"
    }
   },
   "id": "8a686e2f6c000123",
   "execution_count": 318
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kalkuliere welche Kunden die Berater in jeweiligen Jahr betreut haben.\n",
    "Es soll nach Höhe des Aufwands geclustert werden.\n",
    "Hat ein Berater einen Kunden mit mehr als 80 Tagen, so soll dieser Kunde in die Kategorie A fallen.\n",
    "Hat ein Berater einen Kunden mit mehr als 40 Tagen, so soll dieser Kunde in die Kategorie B fallen.\n",
    "Hat ein Berater einen Kunden mit weniger als 40 Tagen, so soll dieser Kunde in die Kategorie C fallen.\n",
    "Hat ein Berater nur Kunden mit weniger als 10 Tagen soll diser in die Kategorie D fallen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f75f99ac9309cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# based on the combined_df dataframe, create a new dataframe with the customers and the categories A, B, C, D per Name\n",
    "\n",
    "# first filter the combined_df dataframe, select the highest value of 'Tage' for each 'Mitarbeiter' and 'Jahr'\n",
    "customers_filtered_highest_df = combined_df.loc[combined_df.groupby(['Mitarbeiter', 'Jahr'])['Tage'].idxmax()]\n",
    "# add a column 'Kategorie' to the dataframe\n",
    "customers_filtered_highest_df['Kategorie'] = ''\n",
    "# set 'Kategorie' to 'D' if 'Tage' is less than 10 for the row in customers_filtered_highest_df\n",
    "customers_filtered_highest_df.loc[customers_filtered_highest_df['Tage'] <= 10, 'Kategorie'] = 'D'\n",
    "# set 'Kategorie' to 'C' if 'Tage' is greater than 40 for the row in customers_filtered_highest_df\n",
    "customers_filtered_highest_df.loc[customers_filtered_highest_df['Tage'] > 10, 'Kategorie'] = 'C'\n",
    "# set 'Kategorie' to 'B' if 'Tage' is greater than 40 for the row in customers_filtered_highest_df\n",
    "customers_filtered_highest_df.loc[customers_filtered_highest_df['Tage'] > 40, 'Kategorie'] = 'B'\n",
    "# set 'Kategorie' to 'A' if 'Tage' is greater than 80 for the row in customers_filtered_highest_df\n",
    "customers_filtered_highest_df.loc[customers_filtered_highest_df['Tage'] > 80, 'Kategorie'] = 'A'\n",
    "# set 'Kategorie' to 'B' if 'Tage' is greater than 40 for the row in customers_filtered_highest_df\n",
    "\n",
    "# save customers_filtered_highest_df to an excel file\n",
    "customers_filtered_highest_df.to_excel('customers_filtered_highest.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:36:43.351657Z",
     "start_time": "2024-01-28T20:36:43.319872Z"
    }
   },
   "id": "358e00823872c8e6",
   "execution_count": 319
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[322], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# map the 'Kategorie' of customers_filtered_highest_df to the input_df dataframe based on 'Mitarbeiter' and 'Jahr' where 'Mitarbeiter' equals 'Name' in the input_df dataframe\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m input_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKategorie\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43minput_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMitarbeiter\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mName\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJahr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJahr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mKategorie\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/frame.py:10347\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m  10333\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m  10335\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m  10336\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10337\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10345\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m  10346\u001B[0m )\n\u001B[0;32m> 10347\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[0;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1063\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1064\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1065\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1079\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m   1080\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m-> 1081\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1082\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m   1083\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[322], line 2\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# map the 'Kategorie' of customers_filtered_highest_df to the input_df dataframe based on 'Mitarbeiter' and 'Jahr' where 'Mitarbeiter' equals 'Name' in the input_df dataframe\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m input_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKategorie\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m input_df\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMitarbeiter\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mName\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcustomers_filtered_highest_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJahr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJahr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mKategorie\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/indexing.py:1192\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1190\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m   1191\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001B[0;32m-> 1192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/indexing.py:1753\u001B[0m, in \u001B[0;36m_iLocIndexer._getitem_axis\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1750\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index by location index with a non-integer key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1752\u001B[0m \u001B[38;5;66;03m# validate the location\u001B[39;00m\n\u001B[0;32m-> 1753\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1755\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_ixs(key, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "File \u001B[0;32m~/miniconda3/envs/pa_ds/lib/python3.11/site-packages/pandas/core/indexing.py:1686\u001B[0m, in \u001B[0;36m_iLocIndexer._validate_integer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1684\u001B[0m len_axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis))\n\u001B[1;32m   1685\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m len_axis \u001B[38;5;129;01mor\u001B[39;00m key \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m-\u001B[39mlen_axis:\n\u001B[0;32m-> 1686\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle positional indexer is out-of-bounds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# map the 'Kategorie' of customers_filtered_highest_df to the input_df dataframe based on 'Mitarbeiter' and 'Jahr' where 'Mitarbeiter' equals 'Name' in the input_df dataframe\n",
    "input_df['Kategorie'] = input_df.apply(lambda row: customers_filtered_highest_df.loc[(customers_filtered_highest_df['Mitarbeiter'] == row['Name']) & (customers_filtered_highest_df['Jahr'] == row['Jahr']), 'Kategorie'].iloc[0], axis=1)  \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:39:28.650Z",
     "start_time": "2024-01-28T20:39:28.610345Z"
    }
   },
   "id": "fe080cdb394daf8e",
   "execution_count": 322
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# filter the data in the dataframe input_df only to show data where alter is not NaN\n",
    "input_df = input_df[input_df['Alter'].notna()]\n",
    "print(input_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4be4a782ccf58031",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save the dataframe to an excel file\n",
    "input_df.to_excel('input_features_filtered.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cc7d622fff3d2d1",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufbau eines Models mit den Input Features.\n",
    "Jahr, Alter, Berufserfahrung, Anzahl Kunden, Bestandskunden\n",
    "Die Target Variable ist die Variable Tage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c40d8b9155585c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare the data for training the model\n",
    "X = input_df[['Alter', 'Berufserfahrung', 'Anzahl Kunden', 'Bestandskunden', 'FIS Umsatz pro Mitarbeiter', 'Workdays', 'Level']]\n",
    "y = input_df['Tage']\n",
    "\n",
    "# Split the data into training and cross validation data - 80% training, 20% cross validation\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'bt_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Evaluate the model with the cross validation data\n",
    "y_pred_cv = model.predict(X_cv)\n",
    "# Evaluate the model with the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Mean Squared Error with the cross validation data\n",
    "mse_cv = mean_squared_error(y_cv, y_pred_cv)\n",
    "# Mean Squared Error with the training data\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "# Calculate the Mean Absolute Error with the cross validation data\n",
    "mae_cv = np.mean(np.abs(y_cv - y_pred_cv))\n",
    "# Calculate the Mean Absolute Error with the training data\n",
    "mae_train = np.mean(np.abs(y_train - y_pred_train))\n",
    "# Root Mean Squared Error with the cross validation data\n",
    "rmse_cv = np.sqrt(mse_cv)\n",
    "# Root Mean Squared Error with the training data\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "print(f'Mean Squared Error CV: {mse_cv}')\n",
    "print(f'Mean Absolute Error CV: {mae_cv}')\n",
    "print(f'Root Mean Squared Error CV: {rmse_cv}')\n",
    "print(f'Mean Squared Error Train: {mse_train}')\n",
    "print(f'Mean Absolute Error Train: {mae_train}')\n",
    "print(f'Root Mean Squared Error Train: {rmse_train}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1158369ddf1d886",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print the y_cv and y_pred_cv values and compare them in a dataframe\n",
    "output_df = pd.DataFrame({'y_cv': y_cv, 'y_pred_cv': y_pred_cv})\n",
    "print(output_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b841bd506c2b6779",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zeige die Korellation der Input Features mit der Target Variable in je einem Scatter Plot.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59ea6e26dc890515"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# show the correlation of the input features with the target variable in a scatter plot\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20, 20))\n",
    "axs[0, 0].scatter(X['Alter'], y)\n",
    "axs[0, 0].set_title('Alter')\n",
    "axs[0, 0].set_xlabel('Alter')\n",
    "axs[0, 0].set_ylabel('Beratertage')\n",
    "axs[0, 1].scatter(X['Berufserfahrung'], y)\n",
    "axs[0, 1].set_title('Berufserfahrung')\n",
    "axs[0, 2].scatter(X['Workdays'], y)\n",
    "axs[0, 2].set_title('Workdays')\n",
    "axs[1, 0].scatter(X['Anzahl Kunden'], y)\n",
    "axs[1, 0].set_title('Anzahl Kunden')\n",
    "axs[1, 1].scatter(X['Bestandskunden'], y)\n",
    "axs[1, 1].set_title('Bestandskunden')\n",
    "#axs[1, 2].scatter(X['Wirtschaftswachstum'], y)\n",
    "#axs[1, 2].set_title('Wirtschaftswachstum')\n",
    "axs[2, 0].scatter(X['FIS Umsatz pro Mitarbeiter'], y)\n",
    "axs[2, 0].set_title('FIS Umsatz pro Mitarbeiter')\n",
    "axs[2, 1].scatter(X['Level'], y)\n",
    "axs[2, 1].set_title('Level')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86aab564fdf55224",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=.5)\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8945f4b8afbc311e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate correlation of each independent variable in X with the target variable y\n",
    "correlation = X.corrwith(y)\n",
    "\n",
    "# create a bar plot of the correlation of each independent variable with the target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation.plot(kind='bar', color='blue')\n",
    "# plot the values of each bar on the bar plot\n",
    "for index, value in enumerate(correlation):\n",
    "    plt.text(index, value, str(round(value, 2)))\n",
    "plt.title('Correlation of the Features with the Target Variable')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ce8fc7e745f5214",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create a pearson correlation test\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# calculate the pearson correlation coefficient and the p-value for the correlation for every feature within X\n",
    "for column in X:\n",
    "    corr, p = pearsonr(X[column], y)\n",
    "    print(f'Pearsons correlation coefficient between {column} and y: {corr}')\n",
    "    print(f'p-value: {p}')\n",
    "    if p > 0.05:\n",
    "        print('The correlation is not significant')\n",
    "    else:\n",
    "        print('The correlation is significant')\n",
    "    print('.......................................................')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66ee0e98b846f24",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nachdem das Model mit Hilfe von Linearer Regression erstellt wurde, wird nun ein Model mit Hilfe eines neuronalen Netzes erstellt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97b96149994730bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and cross validation data - 80% training, 20% cross validation\n",
    "X_train_nn, X_cv_nn, y_train_nn, y_cv_nn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\n",
    "    f\"Using {len(X_train_nn)} records for training \"\n",
    "    f\"and {len(X_cv_nn)} records for cross validation\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d117034886dfeb38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build the neural network model\n",
    "nn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# train the model\n",
    "nn_model.fit(X_train_nn, y_train_nn, epochs=2000)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "105cd973b007d378",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# evaluate the model with the cross validation data\n",
    "print(\"Results for the cross validation data:\")\n",
    "print(nn_model.evaluate(X_cv_nn, y_cv_nn))\n",
    "\n",
    "# evaluate the model with the training data\n",
    "print(\"Results for the training data:\")\n",
    "print(nn_model.evaluate(X_train_nn, y_train_nn))\n",
    "\n",
    "print(\".......................................................\")\n",
    "print(\"Results from the linear regression model:\")\n",
    "print(f'Mean Squared Error CV: {mse_cv}')\n",
    "print(f'Mean Absolute Error CV: {mae_cv}')\n",
    "print(f'Root Mean Squared Error CV: {rmse_cv}')\n",
    "print(f'Mean Squared Error Train: {mse_train}')\n",
    "print(f'Mean Absolute Error Train: {mae_train}')\n",
    "print(f'Root Mean Squared Error Train: {rmse_train}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b1a3faeb8c7c3ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save the tensorflow model to disk\n",
    "nn_model.save('tf_bt_model.keras')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43d9763be84615b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "adf2d53b6c957907",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
